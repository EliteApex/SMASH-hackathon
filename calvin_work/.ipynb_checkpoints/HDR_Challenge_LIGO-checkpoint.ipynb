{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sM_xTC8AN-3i"
   },
   "source": [
    "# Download the data\n",
    "Before running the followiing cell, go to the Challenge page https://www.codabench.org/competitions/2626/ ‚Üí Files and download the `Dataset.zip`. Once downloaded, unzip it, you should have a `Dataset` folder now with three different files inside.\n",
    "\n",
    "Afterwards, load the data to this notebook by clicking üìÅ sign on the left sidebar. Drag and drop the files there. It might take some time to upload the data to the notebook.\n",
    "\n",
    "Now let's load the data and inspect the data, starting with the necessary inputs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'tensorflow[and-cuda]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ~/.nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "ba2UrRNoD_y1",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's start with necessary imports\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.fft import rfft, rfftfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TCz6wPMmAM4"
   },
   "outputs": [],
   "source": [
    "# load data and normalize it\n",
    "background = np.load('../data/background.npz')['data']\n",
    "peak_frequencies = np.zeros((100000, 2))\n",
    "powers = np.zeros((100000, 2))\n",
    "\n",
    "for i in range(background.shape[0]):\n",
    "    for j in range(background.shape[1]):\n",
    "        fft_vals = np.fft.fft(background[i, j])\n",
    "        power_spectrum = np.abs(fft_vals)**2\n",
    "        peak_frequencies[i, j] = np.argmax(power_spectrum)\n",
    "        powers[i, j] = np.sum(power_spectrum)\n",
    "peak_frequencies = peak_frequencies[..., np.newaxis]\n",
    "powers = powers[..., np.newaxis]\n",
    "background = np.concatenate([background, peak_frequencies, powers], axis=2)\n",
    "stds = np.std(background, axis=-1)[:, :, np.newaxis]\n",
    "background = background/stds\n",
    "background = np.swapaxes(background, 1, 2)\n",
    "\n",
    "bbh = np.load('../data/bbh_for_challenge.npy')\n",
    "peak_frequencies = np.zeros((100000, 2))\n",
    "powers = np.zeros((100000, 2))\n",
    "\n",
    "for i in range(bbh.shape[0]):\n",
    "    for j in range(bbh.shape[1]):\n",
    "        fft_vals = np.fft.fft(bbh[i, j])\n",
    "        power_spectrum = np.abs(fft_vals)**2\n",
    "        peak_frequencies[i, j] = np.argmax(power_spectrum)\n",
    "        powers[i, j] = np.sum(power_spectrum)\n",
    "peak_frequencies = peak_frequencies[..., np.newaxis]\n",
    "powers = powers[..., np.newaxis]\n",
    "bbh = np.concatenate([bbh, peak_frequencies, powers], axis=2)\n",
    "stds = np.std(bbh, axis=-1)[:, :, np.newaxis]\n",
    "bbh = bbh/stds\n",
    "bbh = np.swapaxes(bbh, 1, 2)\n",
    "\n",
    "sglf = np.load('../data/sglf_for_challenge.npy')\n",
    "peak_frequencies = np.zeros((100000, 2))\n",
    "powers = np.zeros((100000, 2))\n",
    "\n",
    "for i in range(sglf.shape[0]):\n",
    "    for j in range(sglf.shape[1]):\n",
    "        fft_vals = np.fft.fft(sglf[i, j])\n",
    "        power_spectrum = np.abs(fft_vals)**2\n",
    "        peak_frequencies[i, j] = np.argmax(power_spectrum)\n",
    "        powers[i, j] = np.sum(power_spectrum)\n",
    "peak_frequencies = peak_frequencies[..., np.newaxis]\n",
    "powers = powers[..., np.newaxis]\n",
    "sglf = np.concatenate([sglf, peak_frequencies, powers], axis=2)\n",
    "stds = np.std(sglf, axis=-1)[:, :, np.newaxis]\n",
    "sglf = sglf/stds\n",
    "sglf = np.swapaxes(sglf, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0I4fXnUGqEJ",
    "outputId": "b7922711-0831-428e-d0ab-f8a20dbed419"
   },
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "     background, background, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'x train/test shapes: {x_train.shape} {x_test.shape}')\n",
    "print(f'y train/test shapes: {y_train.shape} {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkDO3cIFEi2-"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Our model processes a tensor of shape `(batch size, sequence length, features)`,\n",
    "where `sequence length` is the number of time steps and `features` is each input\n",
    "timeseries.\n",
    "\n",
    "We include residual connections, layer normalization, and dropout.\n",
    "The resulting layer can be stacked multiple times.\n",
    "\n",
    "The projection layers are implemented through `keras.layers.Conv1D`.\n",
    "\n",
    "The model includes the following components:\n",
    "\n",
    "`Transformer Encoder`: Includes residual connections, layer normalization, dropout, and multi-head attention layers. The projection layers are implemented using `keras.layers.Conv1D`. These layers can be stacked multiple times.\n",
    "\n",
    "`Dense Decoder`: After the transformer encoder, the dense decoder is used. It flattens the input, applies several dense layers with residual connections, dropout, and layer normalization, and then reshapes the output back to the original input shape.\n",
    "\n",
    "The final layer of the model is a dense layer that outputs a tensor of the same shape as the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TruSmroqE13V",
    "outputId": "1c82ffae-f3d3-4e9c-ed08-e0141e4b5e7c"
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transformer_encoder(self, inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "        x = layers.MultiHeadAttention(\n",
    "            key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "        )(inputs, inputs)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        res = x + inputs\n",
    "\n",
    "        x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        return x + res\n",
    "\n",
    "    def dense_decoder(self, inputs, ff_dim, output_dim, dropout=0):\n",
    "        # Flatten the input to apply dense layers\n",
    "        x = layers.Flatten()(inputs)\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        res = layers.Dense(ff_dim)(x)  # Align dimensions for residual\n",
    "\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = x + res\n",
    "\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Dense(np.prod(inputs.shape[1:]))(x)  # Output dimension should match the flattened input dimension\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "        # Reshape back to original input shape\n",
    "        x = layers.Reshape(inputs.shape[1:])(x)\n",
    "        return x + inputs  # Adding input directly, assuming output_dim matches inputs shape[-1]\n",
    "\n",
    "    def build_model(self, input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, num_dense_blocks, dropout=0, mlp_dropout=0):\n",
    "        inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "        # Encoder\n",
    "        x = inputs\n",
    "        for _ in range(num_transformer_blocks):\n",
    "            x = self.transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "        encoder_output = x\n",
    "\n",
    "        # Decoder\n",
    "        x = encoder_output\n",
    "        for _ in range(num_dense_blocks):\n",
    "            x = self.dense_decoder(x, ff_dim, input_shape[-1], dropout)\n",
    "\n",
    "        # Output layer\n",
    "        outputs = layers.Dense(input_shape[-1])(x)\n",
    "\n",
    "        self.ae = keras.Model(inputs, outputs)\n",
    "        self.ae.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "    def predict(self, X, batch_size=32):\n",
    "        return np.mean((self.ae.predict(X, batch_size=batch_size) - X) ** 2, axis=(1,2))\n",
    "\n",
    "    def __call__(self, inputs, batch_size=64):\n",
    "        return self.ae.predict(inputs, batch_size=batch_size)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.ae.save(os.path.join(os.path.dirname(__file__), 'model.keras'))\n",
    "\n",
    "    def load(self):\n",
    "        self.ae = keras.models.load_model(os.path.join(os.path.dirname(__file__), 'model.keras'))\n",
    "\n",
    "    def fit(self, x_train, **kwargs):\n",
    "        history = self.ae.fit(x_train, x_train, **kwargs)\n",
    "        return history\n",
    "\n",
    "# Example usage:\n",
    "input_shape = x_train.shape[1:]\n",
    "head_size = 64\n",
    "num_heads = 2\n",
    "ff_dim = 64\n",
    "num_transformer_blocks = 2\n",
    "num_dense_blocks = 1\n",
    "dropout = 0.1\n",
    "\n",
    "# build the model\n",
    "autoencoder = Model()\n",
    "autoencoder.build_model(\n",
    "    input_shape=input_shape,\n",
    "    head_size=head_size,\n",
    "    num_heads=num_heads,\n",
    "    ff_dim=ff_dim,\n",
    "    num_transformer_blocks=num_transformer_blocks,\n",
    "    num_dense_blocks=num_dense_blocks,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "# Assuming x_train is your input data\n",
    "history = autoencoder.fit(\n",
    "    x_train, # For autoencoders, input is same as output\n",
    "    validation_split=0.2,\n",
    "    epochs=80,\n",
    "    batch_size=32,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DpkaGijejBf"
   },
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "__file__=''\n",
    "!mkdir -p saved_model\n",
    "autoencoder.save('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "m-SDthZeWaVm",
    "outputId": "ccb0e898-60aa-4cf4-95b5-f97c521a9763"
   },
   "outputs": [],
   "source": [
    "# This is just an example; you would probably like to train the model for more epochs\n",
    "metric = \"loss\"\n",
    "plt.figure()\n",
    "plt.plot(history.history[metric])\n",
    "plt.plot(history.history[\"val_\" + metric])\n",
    "plt.title(\"Model \" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "2Ry2LkTGCPeL",
    "outputId": "fcc5325d-5b89-47d2-a1e1-4e98fda65a30"
   },
   "outputs": [],
   "source": [
    "def make_plot_roc_curves(qcd, bsm):\n",
    "\n",
    "    true_val = np.concatenate((np.ones(bsm.shape[0]), np.zeros(qcd.shape[0])))\n",
    "    pred_val = np.concatenate((bsm, qcd))\n",
    "\n",
    "    fpr_loss, tpr_loss, threshold_loss = roc_curve(true_val, pred_val)\n",
    "\n",
    "    auc_loss = auc(fpr_loss, tpr_loss)\n",
    "\n",
    "\n",
    "    qcd[::-1].sort()\n",
    "\n",
    "    plt.plot(fpr_loss, tpr_loss, '-', label=f'MSE (auc = %.1f%%)'%(auc_loss*100.),\n",
    "        linewidth=1.5)\n",
    "    plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n",
    "\n",
    "    plt.semilogx()\n",
    "    plt.semilogy()\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# evaluate on test background and signal samples\n",
    "background_test = autoencoder.predict(x_test)\n",
    "signal_test = autoencoder.predict(bbh)\n",
    "\n",
    "make_plot_roc_curves(background_test, signal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sglf_test = autoencoder.predict(sglf)\n",
    "make_plot_roc_curves(background_test, sglf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "OJVPQXqvUmGJ",
    "outputId": "55468267-082e-44fe-b783-6945041ccb09"
   },
   "outputs": [],
   "source": [
    "plt.hist(background_test, density=True, bins=100, alpha=0.5, label='Background')\n",
    "plt.hist(signal_test, density=True, bins=100, alpha=0.5, label='Signal')\n",
    "plt.semilogy()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Zo1Tb73NnSMe",
    "outputId": "4d1c7ea5-b40f-4215-8d3e-7d16470a232b"
   },
   "outputs": [],
   "source": [
    "pretrained_model = Model()\n",
    "pretrained_model.load()\n",
    "\n",
    "# Check its architecture\n",
    "pretrained_model.ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
