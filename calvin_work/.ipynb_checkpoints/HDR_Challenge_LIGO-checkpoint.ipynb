{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sM_xTC8AN-3i"
   },
   "source": [
    "# Download the data\n",
    "Before running the followiing cell, go to the Challenge page https://www.codabench.org/competitions/2626/ → Files and download the `Dataset.zip`. Once downloaded, unzip it, you should have a `Dataset` folder now with three different files inside.\n",
    "\n",
    "Afterwards, load the data to this notebook by clicking 📁 sign on the left sidebar. Drag and drop the files there. It might take some time to upload the data to the notebook.\n",
    "\n",
    "Now let's load the data and inspect the data, starting with the necessary inputs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow[and-cuda] in /opt/conda/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.17.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow[and-cuda]) (0.37.1)\n",
      "Collecting nvidia-cublas-cu12==12.5.3.2 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cublas_cu12-12.5.3.2-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.3.0.75 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cudnn_cu12-9.3.0.75-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.3.61 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cufft_cu12-11.2.3.61-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.6.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_curand_cu12-10.3.6.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.3.83 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusolver_cu12-11.6.3.83-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.1.3 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusparse_cu12-12.5.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow[and-cuda]) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow[and-cuda]) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow[and-cuda]) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow[and-cuda]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow[and-cuda]) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow[and-cuda]) (0.1.2)\n",
      "Using cached nvidia_cublas_cu12-12.5.3.2-py3-none-manylinux2014_x86_64.whl (363.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvcc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (22.5 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (24.9 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (895 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.3.0.75-py3-none-manylinux2014_x86_64.whl (577.2 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.3.61-py3-none-manylinux2014_x86_64.whl (192.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.6.82-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.3.83-py3-none-manylinux2014_x86_64.whl (130.3 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.1.3-py3-none-manylinux2014_x86_64.whl (217.6 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.2.2+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.2.2+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.2.2+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.2.2+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.2.2+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.2.2+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.2.2+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.2.2+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.2.2+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.2.2+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.21.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.5.3.2 nvidia-cuda-cupti-cu12-12.5.82 nvidia-cuda-nvcc-cu12-12.5.82 nvidia-cuda-nvrtc-cu12-12.5.82 nvidia-cuda-runtime-cu12-12.5.82 nvidia-cudnn-cu12-9.3.0.75 nvidia-cufft-cu12-11.2.3.61 nvidia-curand-cu12-10.3.6.82 nvidia-cusolver-cu12-11.6.3.83 nvidia-cusparse-cu12-12.5.1.3 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.5.82\n"
     ]
    }
   ],
   "source": [
    "!pip install 'tensorflow[and-cuda]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ba2UrRNoD_y1"
   },
   "outputs": [],
   "source": [
    "# Let's start with necessary imports\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.fft import rfft, rfftfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_TCz6wPMmAM4"
   },
   "outputs": [],
   "source": [
    "# load data and normalize it\n",
    "background = np.load('../data/background.npz')['data']\n",
    "stds = np.std(background, axis=-1)[:, :, np.newaxis]\n",
    "background = background/stds\n",
    "peak_frequencies = np.zeros((100000, 2))\n",
    "powers = np.zeros((100000, 2))\n",
    "\n",
    "for i in range(background.shape[0]):\n",
    "    for j in range(background.shape[1]):\n",
    "        fft_vals = np.fft.fft(background[i, j])\n",
    "        power_spectrum = np.abs(fft_vals)**2\n",
    "        peak_frequencies[i, j] = np.argmax(power_spectrum)\n",
    "        powers[i, j] = np.sum(power_spectrum)\n",
    "peak_frequencies = peak_frequencies[..., np.newaxis]\n",
    "powers = powers[..., np.newaxis]\n",
    "background = np.concatenate([background, peak_frequencies, powers], axis=2)\n",
    "background = np.swapaxes(background, 1, 2)\n",
    "\n",
    "bbh = np.load('../data/bbh_for_challenge.npy')\n",
    "stds = np.std(bbh, axis=-1)[:, :, np.newaxis]\n",
    "bbh = bbh/stds\n",
    "peak_frequencies = np.zeros((100000, 2))\n",
    "powers = np.zeros((100000, 2))\n",
    "\n",
    "for i in range(bbh.shape[0]):\n",
    "    for j in range(bbh.shape[1]):\n",
    "        fft_vals = np.fft.fft(bbh[i, j])\n",
    "        power_spectrum = np.abs(fft_vals)**2\n",
    "        peak_frequencies[i, j] = np.argmax(power_spectrum)\n",
    "        powers[i, j] = np.sum(power_spectrum)\n",
    "peak_frequencies = peak_frequencies[..., np.newaxis]\n",
    "powers = powers[..., np.newaxis]\n",
    "bbh = np.concatenate([bbh, peak_frequencies, powers], axis=2)\n",
    "bbh = np.swapaxes(bbh, 1, 2)\n",
    "\n",
    "sglf = np.load('../data/sglf_for_challenge.npy')\n",
    "stds = np.std(sglf, axis=-1)[:, :, np.newaxis]\n",
    "sglf = sglf/stds\n",
    "peak_frequencies = np.zeros((100000, 2))\n",
    "powers = np.zeros((100000, 2))\n",
    "\n",
    "for i in range(sglf.shape[0]):\n",
    "    for j in range(sglf.shape[1]):\n",
    "        fft_vals = np.fft.fft(sglf[i, j])\n",
    "        power_spectrum = np.abs(fft_vals)**2\n",
    "        peak_frequencies[i, j] = np.argmax(power_spectrum)\n",
    "        powers[i, j] = np.sum(power_spectrum)\n",
    "peak_frequencies = peak_frequencies[..., np.newaxis]\n",
    "powers = powers[..., np.newaxis]\n",
    "sglf = np.concatenate([sglf, peak_frequencies, powers], axis=2)\n",
    "sglf = np.swapaxes(sglf, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0I4fXnUGqEJ",
    "outputId": "b7922711-0831-428e-d0ab-f8a20dbed419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train/test shapes: (80000, 202, 2) (20000, 202, 2)\n",
      "y train/test shapes: (80000, 202, 2) (20000, 202, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test datasets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "     background, background, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'x train/test shapes: {x_train.shape} {x_test.shape}')\n",
    "print(f'y train/test shapes: {y_train.shape} {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkDO3cIFEi2-"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Our model processes a tensor of shape `(batch size, sequence length, features)`,\n",
    "where `sequence length` is the number of time steps and `features` is each input\n",
    "timeseries.\n",
    "\n",
    "We include residual connections, layer normalization, and dropout.\n",
    "The resulting layer can be stacked multiple times.\n",
    "\n",
    "The projection layers are implemented through `keras.layers.Conv1D`.\n",
    "\n",
    "The model includes the following components:\n",
    "\n",
    "`Transformer Encoder`: Includes residual connections, layer normalization, dropout, and multi-head attention layers. The projection layers are implemented using `keras.layers.Conv1D`. These layers can be stacked multiple times.\n",
    "\n",
    "`Dense Decoder`: After the transformer encoder, the dense decoder is used. It flattens the input, applies several dense layers with residual connections, dropout, and layer normalization, and then reshapes the output back to the original input shape.\n",
    "\n",
    "The final layer of the model is a dense layer that outputs a tensor of the same shape as the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TruSmroqE13V",
    "outputId": "1c82ffae-f3d3-4e9c-ed08-e0141e4b5e7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 152ms/step - loss: 1651115.3750 - val_loss: 387860.9062\n",
      "Epoch 2/50\n",
      "\u001b[1m 498/2000\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:28\u001b[0m 139ms/step - loss: 339477.0625"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transformer_encoder(self, inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "        x = layers.MultiHeadAttention(\n",
    "            key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "        )(inputs, inputs)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        res = x + inputs\n",
    "\n",
    "        x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        return x + res\n",
    "\n",
    "    def dense_decoder(self, inputs, ff_dim, output_dim, dropout=0):\n",
    "        # Flatten the input to apply dense layers\n",
    "        x = layers.Flatten()(inputs)\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        res = layers.Dense(ff_dim)(x)  # Align dimensions for residual\n",
    "\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = x + res\n",
    "\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Dense(np.prod(inputs.shape[1:]))(x)  # Output dimension should match the flattened input dimension\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "        # Reshape back to original input shape\n",
    "        x = layers.Reshape(inputs.shape[1:])(x)\n",
    "        return x + inputs  # Adding input directly, assuming output_dim matches inputs shape[-1]\n",
    "\n",
    "    def build_model(self, input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, num_dense_blocks, dropout=0, mlp_dropout=0):\n",
    "        inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "        # Encoder\n",
    "        x = inputs\n",
    "        for _ in range(num_transformer_blocks):\n",
    "            x = self.transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "        encoder_output = x\n",
    "\n",
    "        # Decoder\n",
    "        x = encoder_output\n",
    "        for _ in range(num_dense_blocks):\n",
    "            x = self.dense_decoder(x, ff_dim, input_shape[-1], dropout)\n",
    "\n",
    "        # Output layer\n",
    "        outputs = layers.Dense(input_shape[-1])(x)\n",
    "\n",
    "        self.ae = keras.Model(inputs, outputs)\n",
    "        self.ae.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "    def predict(self, X, batch_size=32):\n",
    "        return np.mean((self.ae.predict(X, batch_size=batch_size) - X) ** 2, axis=(1,2))\n",
    "\n",
    "    def __call__(self, inputs, batch_size=64):\n",
    "        return self.ae.predict(inputs, batch_size=batch_size)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.ae.save(os.path.join(os.path.dirname(__file__), 'model.keras'))\n",
    "\n",
    "    def load(self):\n",
    "        self.ae = keras.models.load_model(os.path.join(os.path.dirname(__file__), 'model.keras'))\n",
    "\n",
    "    def fit(self, x_train, **kwargs):\n",
    "        history = self.ae.fit(x_train, x_train, **kwargs)\n",
    "        return history\n",
    "\n",
    "# Example usage:\n",
    "input_shape = x_train.shape[1:]\n",
    "head_size = 64\n",
    "num_heads = 2\n",
    "ff_dim = 64\n",
    "num_transformer_blocks = 2\n",
    "num_dense_blocks = 1\n",
    "dropout = 0.1\n",
    "\n",
    "# build the model\n",
    "autoencoder = Model()\n",
    "autoencoder.build_model(\n",
    "    input_shape=input_shape,\n",
    "    head_size=head_size,\n",
    "    num_heads=num_heads,\n",
    "    ff_dim=ff_dim,\n",
    "    num_transformer_blocks=num_transformer_blocks,\n",
    "    num_dense_blocks=num_dense_blocks,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "# Assuming x_train is your input data\n",
    "history = autoencoder.fit(\n",
    "    x_train, # For autoencoders, input is same as output\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DpkaGijejBf"
   },
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "__file__=''\n",
    "!mkdir -p saved_model\n",
    "autoencoder.save('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "m-SDthZeWaVm",
    "outputId": "ccb0e898-60aa-4cf4-95b5-f97c521a9763"
   },
   "outputs": [],
   "source": [
    "# This is just an example; you would probably like to train the model for more epochs\n",
    "metric = \"loss\"\n",
    "plt.figure()\n",
    "plt.plot(history.history[metric])\n",
    "plt.plot(history.history[\"val_\" + metric])\n",
    "plt.title(\"Model \" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "2Ry2LkTGCPeL",
    "outputId": "fcc5325d-5b89-47d2-a1e1-4e98fda65a30"
   },
   "outputs": [],
   "source": [
    "def make_plot_roc_curves(qcd, bsm):\n",
    "\n",
    "    true_val = np.concatenate((np.ones(bsm.shape[0]), np.zeros(qcd.shape[0])))\n",
    "    pred_val = np.concatenate((bsm, qcd))\n",
    "\n",
    "    fpr_loss, tpr_loss, threshold_loss = roc_curve(true_val, pred_val)\n",
    "\n",
    "    auc_loss = auc(fpr_loss, tpr_loss)\n",
    "\n",
    "\n",
    "    qcd[::-1].sort()\n",
    "\n",
    "    plt.plot(fpr_loss, tpr_loss, '-', label=f'MSE (auc = %.1f%%)'%(auc_loss*100.),\n",
    "        linewidth=1.5)\n",
    "    plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n",
    "\n",
    "    plt.semilogx()\n",
    "    plt.semilogy()\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# evaluate on test background and signal samples\n",
    "background_test = autoencoder.predict(x_test)\n",
    "signal_test = autoencoder.predict(bbh)\n",
    "\n",
    "make_plot_roc_curves(background_test, signal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sglf_test = autoencoder.predict(sglf)\n",
    "make_plot_roc_curves(background_test, sglf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "OJVPQXqvUmGJ",
    "outputId": "55468267-082e-44fe-b783-6945041ccb09"
   },
   "outputs": [],
   "source": [
    "plt.hist(background_test, density=True, bins=100, alpha=0.5, label='Background')\n",
    "plt.hist(signal_test, density=True, bins=100, alpha=0.5, label='Signal')\n",
    "plt.semilogy()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Zo1Tb73NnSMe",
    "outputId": "4d1c7ea5-b40f-4215-8d3e-7d16470a232b"
   },
   "outputs": [],
   "source": [
    "pretrained_model = Model()\n",
    "pretrained_model.load()\n",
    "\n",
    "# Check its architecture\n",
    "pretrained_model.ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
